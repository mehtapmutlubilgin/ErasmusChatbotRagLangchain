import os
import streamlit as st
from langchain_core.prompts import ChatPromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.runnables import RunnablePassthrough
from operator import itemgetter
from dotenv import load_dotenv

# 1. Sabitler ve Kurulum
# Ortam deÄŸiÅŸkenlerini (API anahtarÄ±nÄ±) yÃ¼kle
load_dotenv() 

CHROMA_PATH = "chroma_db"
EMBEDDING_MODEL = "models/text-embedding-004" 
LLM_MODEL = "gemini-2.5-flash" 
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")

if not GEMINI_API_KEY:
    st.error("LÃ¼tfen GEMINI_API_KEY ortam deÄŸiÅŸkenini ayarlayÄ±n (Ã¶rn: set komutuyla veya .env dosyasÄ±nda).")
    st.stop()

# 2. RAG BileÅŸenlerini YÃ¼kleme ve BaÅŸlatma
# @st.cache_resource sayesinde uygulama yeniden yÃ¼klendiÄŸinde bu bileÅŸenler tekrar oluÅŸturulmaz.
@st.cache_resource
def get_rag_chain(api_key):
    # Embedding Modeli ve VektÃ¶r Deposu
    embeddings = GoogleGenerativeAIEmbeddings(
        model=EMBEDDING_MODEL,
        google_api_key=api_key # Anahtar buraya iletildi
    )
    try:
        # VektÃ¶r depoyu yÃ¼kle
        vector_store = Chroma(
            persist_directory=CHROMA_PATH,
            embedding_function=embeddings
        )
        # Retriever (Geri Getirici) oluÅŸtur
        retriever = vector_store.as_retriever(search_kwargs={"k": 3}) 
    except Exception as e:
        st.error(f"VektÃ¶r veritabanÄ± yÃ¼klenirken hata oluÅŸtu. setup_db.py Ã§alÄ±ÅŸtÄ± mÄ±? Hata: {e}")
        st.stop()
        
    # LLM (Large Language Model)
    llm = ChatGoogleGenerativeAI(
        model=LLM_MODEL, 
        temperature=0.1,
        google_api_key=api_key # Anahtar buraya iletildi
    )

    # Prompt Åablonu
    template = """Sen bir Erasmus programÄ± asistanÄ±sÄ±n. Sadece verilen baÄŸlamÄ± kullanarak, kullanÄ±cÄ±nÄ±n sorusuna kibar ve doÄŸru bir yanÄ±t ver.
    EÄŸer baÄŸlamda yeterli bilgi yoksa, 'Bu konuda elimde yeterli bilgi yok.' veya 'Sadece Erasmus programÄ± ile ilgili sorulara yanÄ±t verebilirim.' diye yanÄ±tla.
    
    BaÄŸlam (Context):
    {context}
    
    Soru (Question):
    {question}"""
    
    prompt = ChatPromptTemplate.from_template(template)

    # RAG Zinciri iÃ§in yardÄ±mcÄ± fonksiyon (DokÃ¼manlarÄ± okunabilir metne Ã§evirir)
    def format_docs(docs):
        return "\n\n".join(doc.page_content for doc in docs)

    # Cevap oluÅŸturma zinciri
    rag_chain_from_docs = (
        {
            "context": itemgetter("question") | retriever | format_docs,
            "question": itemgetter("question"),
        }
        | prompt
        | llm
    )
    
    # Ana RAG zinciri (Cevap ve kaynak dokÃ¼manlarÄ± dÃ¶ndÃ¼rmek iÃ§in)
    rag_chain_with_source = RunnablePassthrough.assign(
        context=itemgetter("question") | retriever
    ) | {
        "answer": rag_chain_from_docs,
        "docs": itemgetter("context")
    }

    return rag_chain_with_source

# 3. Streamlit ArayÃ¼zÃ¼
st.set_page_config(page_title="Erasmus RAG Chatbot", layout="wide")
st.title("ğŸ‡ªğŸ‡º Erasmus Bilgi AsistanÄ±")
st.caption("LangChain, ChromaDB ve Gemini ile oluÅŸturulmuÅŸ RAG tabanlÄ± chatbot")

if "messages" not in st.session_state:
    st.session_state.messages = []

# Sohbet geÃ§miÅŸini gÃ¶ster
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# RAG zincirini yÃ¼kle
# AnahtarÄ±n global olarak ayarlandÄ±ÄŸÄ±ndan emin olunduÄŸu iÃ§in burasÄ± Ã§alÄ±ÅŸÄ±r
rag_chain = get_rag_chain(GEMINI_API_KEY)

# KullanÄ±cÄ± giriÅŸi
if prompt := st.chat_input("Erasmus ile ilgili bir soru sorun..."):
    # KullanÄ±cÄ± mesajÄ±nÄ± ekle
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Asistan yanÄ±tÄ±nÄ± oluÅŸtur ve ekle
    with st.spinner("Asistan yanÄ±tÄ± hazÄ±rlanÄ±yor..."):
        # RAG Zincirini Ã§aÄŸÄ±r
        response = rag_chain.invoke({"question": prompt})

        answer = response['answer'].content
        
        # KaynaklarÄ± formatla
        sources = []
        for i, doc in enumerate(response['docs']):
            # CSV Loader'dan gelen metadata'larÄ± kullan
            kategori = doc.metadata.get('kategori', 'N/A')